{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "central-anxiety",
   "metadata": {},
   "source": [
    "## Embedding projector\n",
    "\n",
    "The goal of this practice is to learn how to use the Embedding's Projector of Tensorflow to visualize high-dimensional data easily so that we can understand what a model learns about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import tensorflow as tf # conda install tensorflow -y\n",
    "import tensorflow_hub as hub  # conda install -c conda-forge tensorflow-hub -y\n",
    "import pandas as pd  # conda install pandas -y\n",
    "\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "from skimage.feature.texture import greycomatrix, greycoprops\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-necessity",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-jungle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the data is stored it should be the same that contains the\n",
    "# file projector_config.pbtxt\n",
    "LOG_DIR = \"projector\"\n",
    "\n",
    "# CSV file containing the images path and their corresponding labels\n",
    "CSV_PATH = '' # TODO\n",
    "\n",
    "# Directory of the images\n",
    "IMAGES_DIR = ''# TODO\n",
    "\n",
    "# Info for creating metadata file\n",
    "METADATA_FILE = \"metadata.tsv\"\n",
    "METADATA_PATH = os.path.join(LOG_DIR, METADATA_FILE)\n",
    "\n",
    "# Info for creating sprites\n",
    "IMAGE_SIZE = (64, 64)\n",
    "MAX_NUMBER_SAMPLES = 8191 \n",
    "SPRITES_FILE = os.path.join(LOG_DIR, \"sprites.png\")\n",
    "\n",
    "# Info for feature extraction with CNNs\n",
    "FEATURE_EXTRACTOR_MODEL = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n",
    "INPUT_SHAPE = (224, 224, 3)\n",
    "\n",
    "# Features to extract ('conv_net', 'histogram', 'raw_pixels', 'haralick')\n",
    "TYPE_FEATURES =  '' # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-cleaners",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-perspective",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sprite(data):\n",
    "    \"\"\"\n",
    "    Convert tile images into sprite image. \n",
    "    \"\"\"\n",
    "    # For B&W or grayscale images\n",
    "    if len(data.shape) == 3:\n",
    "        data = np.tile(data[...,np.newaxis], (1,1,1,3))\n",
    "\n",
    "    n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "    padding = ((0, n ** 2 - data.shape[0]), (0, 0), (0, 0), (0, 0))\n",
    "    data = np.pad(data, padding, mode='constant',\n",
    "            constant_values=0)\n",
    "    \n",
    "    # Tile images into sprite\n",
    "    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3, 4))\n",
    "    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-bangkok",
   "metadata": {},
   "source": [
    "### Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file with the name and label of the images\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "df = df[df.label.isin(['others', 'rose', 'sunflower'])]\n",
    "\n",
    "image_files =  df.filename\n",
    "labels = df.label\n",
    "\n",
    "display(df.head())\n",
    "\n",
    "print(len(image_files))\n",
    "\n",
    "df.to_csv('flowers_reduced.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-trial",
   "metadata": {},
   "source": [
    "### Creating sprites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-actress",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = []\n",
    "for img in image_files[:MAX_NUMBER_SAMPLES]:\n",
    "    input_img = imread(os.path.join(IMAGES_DIR, img))\n",
    "    input_img_resize = resize(input_img, IMAGE_SIZE) \n",
    "    img_data.append(input_img_resize)\n",
    "img_data = np.array(img_data)\n",
    "\n",
    "sprite = create_sprite(img_data)\n",
    "imsave(SPRITES_FILE, np.uint8(sprite * 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-flight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing sprites\n",
    "im = imread(SPRITES_FILE)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-buyer",
   "metadata": {},
   "source": [
    "### Creating metadata\n",
    "It contains the filename and class of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-medium",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(METADATA_PATH, 'w') as meta:\n",
    "    writer = csv.writer(meta, delimiter='\\t')\n",
    "    writer.writerow([\"filename\", \"category\"])\n",
    "    for im,lbl in zip(image_files, labels):\n",
    "        writer.writerow([im, lbl])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-macro",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-experiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TYPE_FEATURES == 'haralick':\n",
    "    # write features in a tsv file\n",
    "    with open('./projector/feature_vecs.tsv', 'w') as fw:\n",
    "        csv_writer = csv.writer(fw, delimiter='\\t')\n",
    "        for filename in image_files:\n",
    "            im = imread(os.path.join(IMAGES_DIR, filename))\n",
    "            im = rgb2gray(im) # Convert RGB to GrayScale\n",
    "            im = resize(im, INPUT_SHAPE[:2], anti_aliasing=True)\n",
    "            im = (im * 255).astype(np.uint8)\n",
    "            g = greycomatrix(im, distances=[1], angles=[0, np.pi/2, np.pi/4], \n",
    "                             levels=256, normed=True, symmetric=True)\n",
    "            contrast = greycoprops(g, prop='contrast')\n",
    "            dissimilarity = greycoprops(g, prop='dissimilarity')\n",
    "            homogeneity = greycoprops(g, prop='homogeneity')\n",
    "            energy = greycoprops(g, prop='energy')\n",
    "            correlation = greycoprops(g, prop='correlation')\n",
    "            \n",
    "            f_vector = list(contrast[0]) + list(dissimilarity[0]) + list(homogeneity[0]) + \\\n",
    "                list(energy[0]) + list(correlation[0])\n",
    "            csv_writer.writerows([f_vector])\n",
    "            \n",
    "elif TYPE_FEATURES == 'raw_pixels':\n",
    "    # write features in a tsv file\n",
    "    with open('./projector/feature_vecs.tsv', 'w') as fw:\n",
    "        csv_writer = csv.writer(fw, delimiter='\\t')\n",
    "        for filename in image_files:\n",
    "            im = imread(os.path.join(IMAGES_DIR, filename))\n",
    "            im = rgb2gray(im) # Convert RGB to GrayScale\n",
    "            im = resize(im, INPUT_SHAPE[:2], anti_aliasing=True)\n",
    "            f_vector = im.flatten()\n",
    "            csv_writer.writerows([list(f_vector)])\n",
    "            \n",
    "elif TYPE_FEATURES == 'histogram':\n",
    "    # write features in a tsv file\n",
    "    with open('./projector/feature_vecs.tsv', 'w') as fw:\n",
    "        csv_writer = csv.writer(fw, delimiter='\\t')\n",
    "        for filename in image_files:\n",
    "            im = imread(os.path.join(IMAGES_DIR, filename))\n",
    "            im = rgb2gray(im)\n",
    "            counts, bins = np.histogram(im, np.arange(257)/255)\n",
    "            f_vector = counts/np.sum(counts)\n",
    "            csv_writer.writerows([list(f_vector)])\n",
    "\n",
    "elif TYPE_FEATURES == 'conv_net':\n",
    "    feature_extractor_layer = hub.KerasLayer(FEATURE_EXTRACTOR_MODEL, \n",
    "                                             input_shape=INPUT_SHAPE, trainable=False)\n",
    "\n",
    "    # write features in a tsv file\n",
    "    with open('./projector/feature_vecs.tsv', 'w') as fw:\n",
    "        csv_writer = csv.writer(fw, delimiter='\\t')\n",
    "        for filename in image_files:\n",
    "            im = imread(os.path.join(IMAGES_DIR, filename))\n",
    "            im = resize(im, INPUT_SHAPE[:2], anti_aliasing=True)\n",
    "            im = np.expand_dims(im, axis=0)\n",
    "            f_vector = feature_extractor_layer(im).numpy()[0]\n",
    "            csv_writer.writerows([list(f_vector)])\n",
    "\n",
    "else:\n",
    "    print('SELECTION NOT VALID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-damage",
   "metadata": {},
   "source": [
    "### Start projector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-momentum",
   "metadata": {},
   "source": [
    "Run in the terminal the following command:\n",
    "    - tensorboard --logdir projector\n",
    "    \n",
    "Then in your browser open the following url:\n",
    "    - http://localhost:6006/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
